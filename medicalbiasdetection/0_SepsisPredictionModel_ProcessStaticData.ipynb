{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MBD_Runs/2\n"
     ]
    }
   ],
   "source": [
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Operating System\n",
    "import os\n",
    "\n",
    "# Convenience\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.max_rows', 250)\n",
    "pd.set_option('display.max_columns', 250)\n",
    "\n",
    "\n",
    "from medicalbiasdetection import utils\n",
    "\n",
    "# Global Variables\n",
    "RUN = 1\n",
    "RANDOM_STATE = 0\n",
    "\n",
    "# setup configuration files\n",
    "config = utils.read_yaml()\n",
    "config_preprocessing = utils.read_yaml('conf/mbd_run_log.yaml')\n",
    "config_run = config_preprocessing[RUN]\n",
    "\n",
    "# Create Run Directory\n",
    "utils.create_run_dir(str(RUN))\n",
    "\n",
    "LOG_DIR = config['LOG']['dir'].format(RUN=RUN)\n",
    "LOG_PATH = config['LOG']['path'].format(RUN=RUN)\n",
    "os.environ['LOG_PATH'] = LOG_PATH\n",
    "\n",
    "from medicalbiasdetection import process, cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of encounters (csn): 119733\n",
      "Years: [2016 2017 2018 2019 2020]\n",
      "Start year: 2016\n",
      "End year: 2020\n",
      "Number of unique patient visits: 119733\n",
      "Number of unique patients: 73484\n",
      "Number of sepsis=0 patients: 101269 (84.58%)\n",
      "Number of sepsis=1 patients: 18464 (15.42%)\n"
     ]
    }
   ],
   "source": [
    "# identify the medical facility for the dataset\n",
    "med_fac = 'grady' # 'grady' # 'emory'\n",
    "X = cohort.load_reference_data(med_fac,config, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of encounters (csn): 17798\n",
      "Years: [2016 2017 2018 2019 2020]\n",
      "Start year: 2016\n",
      "End year: 2020\n",
      "Number of unique patient visits: 17798\n",
      "Number of unique patients: 16178\n",
      "Number of sepsis=0 patients: 10538 (59.21%)\n",
      "Number of sepsis=1 patients: 7260 (40.79%)\n",
      "Number of encounters (csn): 17798\n",
      "Years: [2016 2017 2018 2019 2020]\n",
      "Start year: 2016\n",
      "End year: 2020\n",
      "Number of unique patient visits: 17798\n",
      "Number of unique patients: 16178\n",
      "Number of sepsis=0 patients: 10538 (59.21%)\n",
      "Number of sepsis=1 patients: 7260 (40.79%)\n",
      "Number of encounters (csn): 15182\n",
      "Years: [2016 2017 2018 2019 2020]\n",
      "Start year: 2016\n",
      "End year: 2020\n",
      "Number of unique patient visits: 15182\n",
      "Number of unique patients: 13917\n",
      "Number of sepsis=1 patients: 6662 (43.88%)\n",
      "Number of sepsis=0 patients: 8520 (56.12%)\n",
      "Number of encounters (csn): 15179\n",
      "Years: [2016 2017 2018 2019 2020]\n",
      "Start year: 2016\n",
      "End year: 2020\n",
      "Number of unique patient visits: 15179\n",
      "Number of unique patients: 13914\n",
      "Number of sepsis=1 patients: 6662 (43.89%)\n",
      "Number of sepsis=0 patients: 8517 (56.11%)\n",
      "Original Size: 119733\n",
      "Reduced Size: 15179\n",
      "Data Reduction: 104554\n"
     ]
    }
   ],
   "source": [
    "# copy static dataset\n",
    "X_proc = X.copy()\n",
    "n_orig = len(X_proc)\n",
    "\n",
    "# remove non-ICU patients\n",
    "X_proc = X_proc[~X_proc['first_icu_start'].isna()]\n",
    "# print csn report\n",
    "cohort.print_cohort_report(X_proc,'csn','pat_id','sepsis')\n",
    "\n",
    "# remove patients under the age of 18\n",
    "X_proc = X_proc[X_proc['age']>=18]\n",
    "# print csn report\n",
    "cohort.print_cohort_report(X_proc,'csn','pat_id','sepsis')\n",
    "\n",
    "\n",
    "# remove csns with less than 24 hours of data\n",
    "X_proc = X_proc[X_proc['hoursICU']>=24]\n",
    "# print csn report\n",
    "cohort.print_cohort_report(X_proc,'csn','pat_id','sepsis')\n",
    "\n",
    "# remove csns with unknown gender\n",
    "X_proc = X_proc[X_proc['gender']<2]\n",
    "# print csn report\n",
    "cohort.print_cohort_report(X_proc,'csn','pat_id','sepsis')\n",
    "\n",
    "n_reduced = len(X_proc)\n",
    "print(f\"Original Size: {n_orig}\")\n",
    "print(f\"Reduced Size: {n_reduced}\")\n",
    "print(f\"Data Reduction: {n_orig - n_reduced}\")\n",
    "\n",
    "X = X_proc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Missingness amoung Sepsis Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [11:37<00:00, 139.50s/it]\n"
     ]
    }
   ],
   "source": [
    "run_cell = True\n",
    "debug = False\n",
    "\n",
    "if run_cell:\n",
    "    # remove non-sepsis patients\n",
    "    X = X[X['sepsis']==True]\n",
    "    \n",
    "    # set path for results\n",
    "    TYPE = \"sep_patient_missingness\"\n",
    "    file_dir = config['DIR']['data'].format(RUN=RUN, TYPE=TYPE)\n",
    "    filename = \"sepsis_patient_data_hourly.csv\"\n",
    "    outpath = os.path.join(file_dir,filename)\n",
    "    \n",
    "    # init sepsis dataframe\n",
    "    sepsis_df = pd.DataFrame()\n",
    "    \n",
    "    # get pickle dtype map\n",
    "    path = config['data']['pkl_dtypes']\n",
    "    with open(path,\"r\") as file:\n",
    "        pkl_map = json.load(file)\n",
    "\n",
    "    # collect important column names\n",
    "    imp1_cols = [x[0] for x in lab_trt_dict.items() if (x[1]['importance']=='1')] + ['sbp_line','dbp_line','map_line']\n",
    "    \n",
    "    # get list of years to increment for loop\n",
    "    years = np.sort(X.year.unique()).tolist()\n",
    "\n",
    "    # initialize counters\n",
    "    n=0\n",
    "    save_i = 0\n",
    "\n",
    "    # loop through each year\n",
    "    for year in (tqdm(years,leave=True)):\n",
    "        \n",
    "        # convert year to int\n",
    "        year = int(year)\n",
    "\n",
    "        # filter data by year\n",
    "        data = X[X.year==year]\n",
    "\n",
    "        # loop through each patient \n",
    "        for ind,row in data.iterrows():\n",
    "\n",
    "            # patient csn\n",
    "            csn = row.csn\n",
    "\n",
    "            # first hour of icu status\n",
    "            icu_start_time = row.first_icu_start\n",
    "\n",
    "            # first hour of hospital admission\n",
    "            hosp_admit = row.start_index\n",
    "\n",
    "            # sepsis (bool)\n",
    "            sepsis = row.sepsis\n",
    "\n",
    "            try:\n",
    "                # create path to patient ehr data\n",
    "                path = config['data']['pat_pkl'].format(year=year,csn=csn)\n",
    "\n",
    "                # ingest patient data file\n",
    "                p_pkl = pd.read_pickle(path) \n",
    "\n",
    "                # get super_table (time-series) EMR data\n",
    "                hosp_data = p_pkl[\"super_table\"].copy()\n",
    "\n",
    "                # assign data types to each column\n",
    "                hosp_data = hosp_data.astype(pkl_map,errors='ignore')\n",
    "\n",
    "                # keep columns of importance 1\n",
    "                hosp_data = hosp_data[imp1_cols]\n",
    "\n",
    "                # assign csn\n",
    "                hosp_data['csn'] = csn\n",
    "\n",
    "                # shift df to icu start time to remove information collected outside of the icu\n",
    "                hosp_data = hosp_data.loc[icu_start_time:]\n",
    "\n",
    "                if not debug:\n",
    "                    hosp_data.to_csv(outpath, mode='a', header=not os.path.exists(outpath))\n",
    "\n",
    "                # increment patient index counter\n",
    "                n+=1\n",
    "\n",
    "                if debug:\n",
    "                    stop =2\n",
    "                    if n >= stop:\n",
    "                        break\n",
    "\n",
    "            except:\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read Sepsis Patient Hourly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get filepath\n",
    "TYPE = \"sep_patient_missingness\"\n",
    "file_dir = config['DIR']['data'].format(RUN=RUN, TYPE=TYPE)\n",
    "filename = \"sepsis_patient_data_hourly.csv\"\n",
    "filepath = os.path.join(file_dir,filename)\n",
    "\n",
    "# read file\n",
    "sep_df = pd.read_csv(filepath, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculate Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = pd.DataFrame(sep_df.isna().sum(axis=0)).reset_index().rename(columns={'index':'column',0:'n'})\n",
    "missing['perc'] = missing['n']/sep_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ID columns with more than 75% of data missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ammonia',\n",
       " 'amylase',\n",
       " 'b-type_natriuretic_peptide_(bnp)',\n",
       " 'crp_high_sens',\n",
       " 'd_dimer',\n",
       " 'dobutamine_dose_weight',\n",
       " 'dopamine_dose_weight',\n",
       " 'epinephrine_dose_weight',\n",
       " 'erythrocyte_sedimentation_rate_(esr)',\n",
       " 'fibrinogen',\n",
       " 'hemoglobin_a1c',\n",
       " 'inr',\n",
       " 'lactic_acid',\n",
       " 'lipase',\n",
       " 'norepinephrine_dose_weight',\n",
       " 'parathyroid_level',\n",
       " 'partial_prothrombin_time_(ptt)',\n",
       " 'phenylephrine_dose_weight',\n",
       " 'prealbumin',\n",
       " 'procalcitonin',\n",
       " 'prothrombin_time_(pt)',\n",
       " 'saturation_of_oxygen_(sao2)',\n",
       " 'thrombin_time',\n",
       " 'thyroid_stimulating_hormone_(tsh)',\n",
       " 'transferrin',\n",
       " 'troponin',\n",
       " 'vasopressin_dose_weight',\n",
       " 'sbp_line',\n",
       " 'dbp_line']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# leave sbp_line, and dbp_line\n",
    "missing[missing['perc']>.75]['column'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of encounters (csn): 119733\n",
      "Years: [2016 2017 2018 2019 2020]\n",
      "Start year: 2016\n",
      "End year: 2020\n",
      "Number of unique patient visits: 119733\n",
      "Number of unique patients: 73484\n",
      "Number of sepsis=0 patients: 101269 (84.58%)\n",
      "Number of sepsis=1 patients: 18464 (15.42%)\n"
     ]
    }
   ],
   "source": [
    "# identify the medical facility for the dataset\n",
    "med_fac = 'grady' # 'grady' # 'emory'\n",
    "X = cohort.load_reference_data(med_fac,config, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of encounters (csn): 17798\n",
      "Years: [2016 2017 2018 2019 2020]\n",
      "Start year: 2016\n",
      "End year: 2020\n",
      "Number of unique patient visits: 17798\n",
      "Number of unique patients: 16178\n",
      "Number of sepsis=0 patients: 10538 (59.21%)\n",
      "Number of sepsis=1 patients: 7260 (40.79%)\n",
      "Number of encounters (csn): 17798\n",
      "Years: [2016 2017 2018 2019 2020]\n",
      "Start year: 2016\n",
      "End year: 2020\n",
      "Number of unique patient visits: 17798\n",
      "Number of unique patients: 16178\n",
      "Number of sepsis=0 patients: 10538 (59.21%)\n",
      "Number of sepsis=1 patients: 7260 (40.79%)\n",
      "Number of encounters (csn): 15182\n",
      "Years: [2016 2017 2018 2019 2020]\n",
      "Start year: 2016\n",
      "End year: 2020\n",
      "Number of unique patient visits: 15182\n",
      "Number of unique patients: 13917\n",
      "Number of sepsis=1 patients: 6662 (43.88%)\n",
      "Number of sepsis=0 patients: 8520 (56.12%)\n",
      "Number of encounters (csn): 15179\n",
      "Years: [2016 2017 2018 2019 2020]\n",
      "Start year: 2016\n",
      "End year: 2020\n",
      "Number of unique patient visits: 15179\n",
      "Number of unique patients: 13914\n",
      "Number of sepsis=1 patients: 6662 (43.89%)\n",
      "Number of sepsis=0 patients: 8517 (56.11%)\n",
      "Original Size: 119733\n",
      "Reduced Size: 15179\n",
      "Data Reduction: 104554\n"
     ]
    }
   ],
   "source": [
    "# copy static dataset\n",
    "X_proc = X.copy()\n",
    "n_orig = len(X_proc)\n",
    "\n",
    "# remove non-ICU patients\n",
    "X_proc = X_proc[~X_proc['first_icu_start'].isna()]\n",
    "# print csn report\n",
    "cohort.print_cohort_report(X_proc,'csn','pat_id','sepsis')\n",
    "\n",
    "# remove patients under the age of 18\n",
    "X_proc = X_proc[X_proc['age']>=18]\n",
    "# print csn report\n",
    "cohort.print_cohort_report(X_proc,'csn','pat_id','sepsis')\n",
    "\n",
    "\n",
    "# remove csns with less than 24 hours of data\n",
    "X_proc = X_proc[X_proc['hoursICU']>=24]\n",
    "# print csn report\n",
    "cohort.print_cohort_report(X_proc,'csn','pat_id','sepsis')\n",
    "\n",
    "# remove csns with unknown gender\n",
    "X_proc = X_proc[X_proc['gender']<2]\n",
    "# print csn report\n",
    "cohort.print_cohort_report(X_proc,'csn','pat_id','sepsis')\n",
    "\n",
    "n_reduced = len(X_proc)\n",
    "print(f\"Original Size: {n_orig}\")\n",
    "print(f\"Reduced Size: {n_reduced}\")\n",
    "print(f\"Data Reduction: {n_orig - n_reduced}\")\n",
    "\n",
    "X = X_proc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate feature statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [41:15<00:00, 495.17s/it]\n"
     ]
    }
   ],
   "source": [
    "run_cell = True\n",
    "debug = False\n",
    "\n",
    "if run_cell:\n",
    "\n",
    "    # get pickle dtype map\n",
    "    path = config['data']['pkl_dtypes']\n",
    "    with open(path,\"r\") as file:\n",
    "        pkl_map = json.load(file)\n",
    "\n",
    "    # collect important column names\n",
    "    imp1_cols = [x[0] for x in lab_trt_dict.items() if (x[1]['importance']=='1')] #+ ['sbp_line','dbp_line','map_line']\n",
    "\n",
    "    # columns to drop\n",
    "    drop_missing = config['preprocess']['drop_missing']\n",
    "    \n",
    "    # list of feature statistics to collect for each patient\n",
    "    functions = ['min','max','mean']\n",
    "\n",
    "    # get list of years to increment for loop\n",
    "    years = np.sort(X.year.unique()).tolist()\n",
    "\n",
    "    # init counters\n",
    "    n=0\n",
    "    save_i = 0\n",
    "\n",
    "    patient_features_df = pd.DataFrame()\n",
    "    patient_features = []\n",
    "\n",
    "    # loop through each year\n",
    "    for year in (tqdm(years)):\n",
    "\n",
    "        # filter data by year\n",
    "        data = X[X.year==year]\n",
    "\n",
    "        # loop through each patient \n",
    "        for ind,row in data.iterrows():\n",
    "\n",
    "            # patient csn\n",
    "            csn = row.csn\n",
    "                \n",
    "            # first hour of icu status\n",
    "            icu_start_time = row.first_icu_start\n",
    "\n",
    "            # sepsis [False,True]\n",
    "            sepsis = row.sepsis\n",
    "\n",
    "            try:\n",
    "\n",
    "                # create path to patient ehr data\n",
    "                path = config['data']['pat_pkl'].format(year=year,csn=csn)\n",
    "\n",
    "                # ingest patient data file\n",
    "                p_pkl = pd.read_pickle(path) \n",
    "\n",
    "                # get super_table (time-series) EMR data\n",
    "                hosp_data = p_pkl[\"super_table\"].copy()\n",
    "\n",
    "                # assign data types\n",
    "                hosp_data = hosp_data.astype(pkl_map,errors='ignore')\n",
    "\n",
    "                # keep columns of importance 1\n",
    "                hosp_data = hosp_data[imp1_cols]\n",
    "\n",
    "                # drop missing columns\n",
    "                hosp_data = hosp_data.drop(columns=drop_missing, errors='ignore')\n",
    "\n",
    "                pat_feat_list = hosp_data.columns\n",
    "\n",
    "                # shift df to icu start time to remove information collected outside of the icu\n",
    "                hosp_data = hosp_data.loc[icu_start_time:]\n",
    "\n",
    "                # apply the list of functions to each column\n",
    "                stats_df = hosp_data[pat_feat_list].agg(functions).T\n",
    "\n",
    "                # stack features to create multi-index dataframe\n",
    "                pat_features = stats_df.stack().to_frame().T\n",
    "\n",
    "                # combine indexes to create column names\n",
    "                pat_features.columns = ['{}_{}'.format(*col) for col in pat_features.columns]\n",
    "\n",
    "                # assign patient csn as reference\n",
    "                pat_features['csn'] = csn\n",
    "\n",
    "                for col in pat_features.columns:\n",
    "                    pat_features[col] = pd.to_numeric(pat_features[col],errors='coerce',)\n",
    "\n",
    "                # clean aggregated patient feature data\n",
    "                pat_features.fillna(np.nan, inplace=True)\n",
    "                pat_features = pat_features.round(4)\n",
    "\n",
    "                # append data to patient list\n",
    "                patient_features.append(pat_features)\n",
    "\n",
    "                # increment patient index counter\n",
    "                n+=1\n",
    "\n",
    "                if debug:\n",
    "                    stop = 5\n",
    "                    if n >= stop:\n",
    "                        break\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    \n",
    "    # save patient features\n",
    "    TYPE = 'static'\n",
    "    static_dir = config['DIR']['data'].format(RUN=RUN,TYPE=TYPE)\n",
    "    filename = \"processed_data_patient_features.csv\"\n",
    "    pat_feat_outpath = os.path.join(static_dir,filename)\n",
    "\n",
    "    # combine patient feature data into dataframe\n",
    "    final = pd.concat(patient_features,axis=0)\n",
    "    if not debug:\n",
    "        # save\n",
    "        final.to_csv(pat_feat_outpath)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
