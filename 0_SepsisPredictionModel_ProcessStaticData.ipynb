{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MBD_Runs/3\n"
     ]
    }
   ],
   "source": [
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Operating System\n",
    "import os\n",
    "\n",
    "# Convenience\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.max_rows', 250)\n",
    "pd.set_option('display.max_columns', 250)\n",
    "\n",
    "\n",
    "from medicalbiasdetection import utils\n",
    "\n",
    "# Global Variables\n",
    "RUN = 3\n",
    "RANDOM_STATE = 0\n",
    "\n",
    "# setup configuration files\n",
    "config = utils.read_yaml()\n",
    "config_preprocessing = utils.read_yaml('conf/mbd_run_log.yaml')\n",
    "config_run = config_preprocessing[RUN]\n",
    "\n",
    "# Create Run Directory\n",
    "utils.create_run_dir(str(RUN))\n",
    "\n",
    "LOG_DIR = config['LOG']['dir'].format(RUN=RUN)\n",
    "LOG_PATH = config['LOG']['path'].format(RUN=RUN)\n",
    "os.environ['LOG_PATH'] = LOG_PATH\n",
    "os.environ['RUN'] = str(RUN)\n",
    "\n",
    "from medicalbiasdetection import process, cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of encounters (csn): 119733\n",
      "Years: [2016 2017 2018 2019 2020]\n",
      "Start year: 2016\n",
      "End year: 2020\n",
      "Number of unique patient visits: 119733\n",
      "Number of unique patients: 73484\n",
      "Number of sepsis=0 patients: 101269 (84.58%)\n",
      "Number of sepsis=1 patients: 18464 (15.42%)\n"
     ]
    }
   ],
   "source": [
    "# get columns that will be converted to datetime \n",
    "time_cols = config['meta']['time_cols']\n",
    "\n",
    "# get associated data types for each column\n",
    "with open(config['data']['sep3_dtypes'],\"r\") as file:\n",
    "    data_types = json.load(file)\n",
    "\n",
    "# get lab and treatment labels    \n",
    "with open(config['data']['lab_treatment_dict'],\"r\") as file:\n",
    "    lab_trt_dict = json.load(file)\n",
    "\n",
    "# identify the medical facility for the dataset\n",
    "med_fac = 'grady' # 'grady' # 'emory'\n",
    "X = cohort.load_reference_data(med_fac,config, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of encounters (csn): 17798\n",
      "Years: [2016 2017 2018 2019 2020]\n",
      "Start year: 2016\n",
      "End year: 2020\n",
      "Number of unique patient visits: 17798\n",
      "Number of unique patients: 16178\n",
      "Number of sepsis=0 patients: 10538 (59.21%)\n",
      "Number of sepsis=1 patients: 7260 (40.79%)\n",
      "Number of encounters (csn): 17798\n",
      "Years: [2016 2017 2018 2019 2020]\n",
      "Start year: 2016\n",
      "End year: 2020\n",
      "Number of unique patient visits: 17798\n",
      "Number of unique patients: 16178\n",
      "Number of sepsis=0 patients: 10538 (59.21%)\n",
      "Number of sepsis=1 patients: 7260 (40.79%)\n",
      "Number of encounters (csn): 15182\n",
      "Years: [2016 2017 2018 2019 2020]\n",
      "Start year: 2016\n",
      "End year: 2020\n",
      "Number of unique patient visits: 15182\n",
      "Number of unique patients: 13917\n",
      "Number of sepsis=1 patients: 6662 (43.88%)\n",
      "Number of sepsis=0 patients: 8520 (56.12%)\n",
      "Number of encounters (csn): 15179\n",
      "Years: [2016 2017 2018 2019 2020]\n",
      "Start year: 2016\n",
      "End year: 2020\n",
      "Number of unique patient visits: 15179\n",
      "Number of unique patients: 13914\n",
      "Number of sepsis=1 patients: 6662 (43.89%)\n",
      "Number of sepsis=0 patients: 8517 (56.11%)\n",
      "Original Size: 119733\n",
      "Reduced Size: 15179\n",
      "Data Reduction: 104554\n"
     ]
    }
   ],
   "source": [
    "# copy static dataset\n",
    "X_proc = X.copy()\n",
    "n_orig = len(X_proc)\n",
    "\n",
    "# remove non-ICU patients\n",
    "X_proc = X_proc[~X_proc['first_icu_start'].isna()]\n",
    "# print csn report\n",
    "cohort.print_cohort_report(X_proc,'csn','pat_id','sepsis')\n",
    "\n",
    "# remove patients under the age of 18\n",
    "X_proc = X_proc[X_proc['age']>=18]\n",
    "# print csn report\n",
    "cohort.print_cohort_report(X_proc,'csn','pat_id','sepsis')\n",
    "\n",
    "\n",
    "# remove csns with less than 24 hours of data\n",
    "X_proc = X_proc[X_proc['hoursICU']>=24]\n",
    "# print csn report\n",
    "cohort.print_cohort_report(X_proc,'csn','pat_id','sepsis')\n",
    "\n",
    "# remove csns with unknown gender\n",
    "X_proc = X_proc[X_proc['gender']<2]\n",
    "# print csn report\n",
    "cohort.print_cohort_report(X_proc,'csn','pat_id','sepsis')\n",
    "\n",
    "n_reduced = len(X_proc)\n",
    "print(f\"Original Size: {n_orig}\")\n",
    "print(f\"Reduced Size: {n_reduced}\")\n",
    "print(f\"Data Reduction: {n_orig - n_reduced}\")\n",
    "\n",
    "X = X_proc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [30:30<00:00, 366.09s/it]\n"
     ]
    }
   ],
   "source": [
    "run_cell = True\n",
    "debug = False\n",
    "\n",
    "if run_cell:\n",
    "\n",
    "    # set path for results\n",
    "    TYPE = \"sep_patient_missingness\"\n",
    "    file_dir = config['DIR']['data'].format(RUN=RUN, TYPE=TYPE)\n",
    "    filename = \"sepsis_patient_data_hourly.csv\"\n",
    "    outpath = os.path.join(file_dir,filename)\n",
    "    \n",
    "    # init sepsis dataframe\n",
    "    sepsis_df = pd.DataFrame()\n",
    "    \n",
    "    # get pickle dtype map\n",
    "    pkl_map = config['pkl_dtypes']\n",
    "\n",
    "    # collect important column names\n",
    "    imp1_cols = [x[0] for x in lab_trt_dict.items() if (x[1]['importance']=='1')] + ['sbp_line','dbp_line','map_line','sbp_cuff','dbp_cuff','map_cuff']\n",
    "    \n",
    "    # get list of years to increment for loop\n",
    "    years = np.sort(X.year.unique()).tolist()\n",
    "\n",
    "    # initialize counters\n",
    "    n=0\n",
    "    save_i = 0\n",
    "\n",
    "    # loop through each year\n",
    "    for year in (tqdm(years,leave=True)):\n",
    "        \n",
    "        # convert year to int\n",
    "        year = int(year)\n",
    "\n",
    "        # filter data by year\n",
    "        data = X[X.year==year]\n",
    "\n",
    "        # loop through each patient \n",
    "        for ind,row in data.iterrows():\n",
    "\n",
    "            # patient csn\n",
    "            csn = row.csn\n",
    "\n",
    "            # first hour of icu status\n",
    "            icu_start_time = row.first_icu_start\n",
    "\n",
    "            # first hour of hospital admission\n",
    "            hosp_admit = row.start_index\n",
    "\n",
    "            # sepsis (bool)\n",
    "            sepsis = row.sepsis\n",
    "\n",
    "            try:\n",
    "                # create path to patient ehr data\n",
    "                path = config['data']['pat_pkl'].format(year=year,csn=csn)\n",
    "\n",
    "                # ingest patient data file\n",
    "                p_pkl = pd.read_pickle(path) \n",
    "\n",
    "                # get super_table (time-series) EMR data\n",
    "                hosp_data = p_pkl[\"super_table\"].copy()\n",
    "\n",
    "                # assign data types to each column\n",
    "                hosp_data = hosp_data.astype(pkl_map,errors='ignore')\n",
    "                \n",
    "                # fill appropriate na values\n",
    "                hosp_data = hosp_data.fillna(value = config['fill_na'])\n",
    "            \n",
    "                # keep columns of importance 1\n",
    "                hosp_data = hosp_data[imp1_cols]\n",
    "\n",
    "                # assign csn\n",
    "                hosp_data['csn'] = csn\n",
    "\n",
    "                # shift df to icu start time to remove information collected outside of the icu\n",
    "                hosp_data = hosp_data.loc[icu_start_time:]\n",
    "\n",
    "                if not debug:\n",
    "                    hosp_data.to_csv(outpath, mode='a', header=not os.path.exists(outpath))\n",
    "\n",
    "                # increment patient index counter\n",
    "                n+=1\n",
    "\n",
    "                if debug:\n",
    "                    stop =5\n",
    "                    if n >= stop:\n",
    "                        break\n",
    "\n",
    "            except:\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read Sepsis Patient Hourly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get filepath\n",
    "TYPE = \"sep_patient_missingness\"\n",
    "file_dir = config['DIR']['data'].format(RUN=RUN, TYPE=TYPE)\n",
    "filename = \"sepsis_patient_data_hourly.csv\"\n",
    "filepath = os.path.join(file_dir,filename)\n",
    "\n",
    "# read file\n",
    "sep_df = pd.read_csv(filepath, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculate Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = pd.DataFrame(sep_df.isna().sum(axis=0)).reset_index().rename(columns={'index':'column',0:'n'})\n",
    "missing['perc'] = missing['n']/sep_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ID columns with more than 75% of data missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ammonia\n",
      "amylase\n",
      "b-type_natriuretic_peptide_(bnp)\n",
      "crp_high_sens\n",
      "d_dimer\n",
      "dobutamine_dose_weight\n",
      "dopamine_dose_weight\n",
      "epinephrine_dose_weight\n",
      "erythrocyte_sedimentation_rate_(esr)\n",
      "fibrinogen\n",
      "hemoglobin_a1c\n",
      "inr\n",
      "lactic_acid\n",
      "lipase\n",
      "norepinephrine_dose_weight\n",
      "parathyroid_level\n",
      "partial_prothrombin_time_(ptt)\n",
      "pf_pa\n",
      "phenylephrine_dose_weight\n",
      "prealbumin\n",
      "procalcitonin\n",
      "prothrombin_time_(pt)\n",
      "saturation_of_oxygen_(sao2)\n",
      "thrombin_time\n",
      "thyroid_stimulating_hormone_(tsh)\n",
      "transferrin\n",
      "troponin\n",
      "vasopressin_dose_weight\n",
      "sbp_line\n",
      "dbp_line\n",
      "map_line\n"
     ]
    }
   ],
   "source": [
    "missing_cols = missing[missing['perc']>.75]['column'].tolist()\n",
    "for col in missing_cols:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of encounters (csn): 119733\n",
      "Years: [2016 2017 2018 2019 2020]\n",
      "Start year: 2016\n",
      "End year: 2020\n",
      "Number of unique patient visits: 119733\n",
      "Number of unique patients: 73484\n",
      "Number of sepsis=0 patients: 101269 (84.58%)\n",
      "Number of sepsis=1 patients: 18464 (15.42%)\n"
     ]
    }
   ],
   "source": [
    "# get columns that will be converted to datetime \n",
    "time_cols = config['meta']['time_cols']\n",
    "\n",
    "# get associated data types for each column\n",
    "with open(config['data']['sep3_dtypes'],\"r\") as file:\n",
    "    data_types = json.load(file)\n",
    "\n",
    "# get lab and treatment labels    \n",
    "with open(config['data']['lab_treatment_dict'],\"r\") as file:\n",
    "    lab_trt_dict = json.load(file)\n",
    "\n",
    "# identify the medical facility for the dataset\n",
    "med_fac = 'grady' # 'grady' # 'emory'\n",
    "X = cohort.load_reference_data(med_fac,config, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of encounters (csn): 17798\n",
      "Years: [2016 2017 2018 2019 2020]\n",
      "Start year: 2016\n",
      "End year: 2020\n",
      "Number of unique patient visits: 17798\n",
      "Number of unique patients: 16178\n",
      "Number of sepsis=0 patients: 10538 (59.21%)\n",
      "Number of sepsis=1 patients: 7260 (40.79%)\n",
      "Number of encounters (csn): 17798\n",
      "Years: [2016 2017 2018 2019 2020]\n",
      "Start year: 2016\n",
      "End year: 2020\n",
      "Number of unique patient visits: 17798\n",
      "Number of unique patients: 16178\n",
      "Number of sepsis=0 patients: 10538 (59.21%)\n",
      "Number of sepsis=1 patients: 7260 (40.79%)\n",
      "Number of encounters (csn): 15182\n",
      "Years: [2016 2017 2018 2019 2020]\n",
      "Start year: 2016\n",
      "End year: 2020\n",
      "Number of unique patient visits: 15182\n",
      "Number of unique patients: 13917\n",
      "Number of sepsis=1 patients: 6662 (43.88%)\n",
      "Number of sepsis=0 patients: 8520 (56.12%)\n",
      "Number of encounters (csn): 15179\n",
      "Years: [2016 2017 2018 2019 2020]\n",
      "Start year: 2016\n",
      "End year: 2020\n",
      "Number of unique patient visits: 15179\n",
      "Number of unique patients: 13914\n",
      "Number of sepsis=1 patients: 6662 (43.89%)\n",
      "Number of sepsis=0 patients: 8517 (56.11%)\n",
      "Original Size: 119733\n",
      "Reduced Size: 15179\n",
      "Data Reduction: 104554\n"
     ]
    }
   ],
   "source": [
    "# copy static dataset\n",
    "X_proc = X.copy()\n",
    "n_orig = len(X_proc)\n",
    "\n",
    "# remove non-ICU patients\n",
    "X_proc = X_proc[~X_proc['first_icu_start'].isna()]\n",
    "# print csn report\n",
    "cohort.print_cohort_report(X_proc,'csn','pat_id','sepsis')\n",
    "\n",
    "# remove patients under the age of 18\n",
    "X_proc = X_proc[X_proc['age']>=18]\n",
    "# print csn report\n",
    "cohort.print_cohort_report(X_proc,'csn','pat_id','sepsis')\n",
    "\n",
    "\n",
    "# remove csns with less than 24 hours of data\n",
    "X_proc = X_proc[X_proc['hoursICU']>=24]\n",
    "# print csn report\n",
    "cohort.print_cohort_report(X_proc,'csn','pat_id','sepsis')\n",
    "\n",
    "# remove csns with unknown gender\n",
    "X_proc = X_proc[X_proc['gender']<2]\n",
    "# print csn report\n",
    "cohort.print_cohort_report(X_proc,'csn','pat_id','sepsis')\n",
    "\n",
    "n_reduced = len(X_proc)\n",
    "print(f\"Original Size: {n_orig}\")\n",
    "print(f\"Reduced Size: {n_reduced}\")\n",
    "print(f\"Data Reduction: {n_orig - n_reduced}\")\n",
    "\n",
    "X = X_proc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate feature statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [34:19<00:00, 411.81s/it]\n"
     ]
    }
   ],
   "source": [
    "run_cell = False\n",
    "debug = False\n",
    "\n",
    "if run_cell:\n",
    "\n",
    "    # get pickle dtype map\n",
    "    pkl_map = config['pkl_dtypes']\n",
    "\n",
    "    # collect important column names\n",
    "    imp1_cols = [x[0] for x in lab_trt_dict.items() if (x[1]['importance']=='1')] + ['sbp_cuff','dbp_cuff','map_cuff']\n",
    "\n",
    "    # columns to drop\n",
    "    drop_missing = config['preprocess']['drop_missing']\n",
    "    \n",
    "    # list of feature statistics to collect for each patient\n",
    "    functions = ['min','max','mean']\n",
    "\n",
    "    # get list of years to increment for loop\n",
    "    years = np.sort(X.year.unique()).tolist()\n",
    "\n",
    "    # init counters\n",
    "    n=0\n",
    "    save_i = 0\n",
    "\n",
    "    patient_features_df = pd.DataFrame()\n",
    "    patient_features = []\n",
    "\n",
    "    # loop through each year\n",
    "    for year in (tqdm(years)):\n",
    "\n",
    "        # filter data by year\n",
    "        data = X[X.year==year]\n",
    "\n",
    "        # loop through each patient \n",
    "        for ind,row in data.iterrows():\n",
    "\n",
    "            # patient csn\n",
    "            csn = row.csn\n",
    "                \n",
    "            # first hour of icu status\n",
    "            icu_start_time = row.first_icu_start\n",
    "\n",
    "            # sepsis [False,True]\n",
    "            sepsis = row.sepsis\n",
    "\n",
    "            try:\n",
    "\n",
    "                # create path to patient ehr data\n",
    "                path = config['data']['pat_pkl'].format(year=year,csn=csn)\n",
    "\n",
    "                # ingest patient data file\n",
    "                p_pkl = pd.read_pickle(path) \n",
    "\n",
    "                # get super_table (time-series) EMR data\n",
    "                hosp_data = p_pkl[\"super_table\"].copy()\n",
    "\n",
    "                # assign data types\n",
    "                hosp_data = hosp_data.astype(pkl_map,errors='ignore')\n",
    "                \n",
    "                # fill appropriate na values\n",
    "                hosp_data = hosp_data.fillna(value = config['fill_na'])\n",
    "                \n",
    "                # keep columns of importance 1\n",
    "                hosp_data = hosp_data[imp1_cols]\n",
    "\n",
    "                # drop missing columns\n",
    "                hosp_data = hosp_data.drop(columns=drop_missing, errors='ignore')\n",
    "\n",
    "                pat_feat_list = hosp_data.columns\n",
    "\n",
    "                # shift df to icu start time to remove information collected outside of the icu\n",
    "                hosp_data = hosp_data.loc[icu_start_time:]\n",
    "\n",
    "                # apply the list of functions to each column\n",
    "                stats_df = hosp_data[pat_feat_list].agg(functions).T\n",
    "\n",
    "                # stack features to create multi-index dataframe\n",
    "                pat_features = stats_df.stack().to_frame().T\n",
    "\n",
    "                # combine indexes to create column names\n",
    "                pat_features.columns = ['{}_{}'.format(*col) for col in pat_features.columns]\n",
    "\n",
    "                # assign patient csn as reference\n",
    "                pat_features['csn'] = csn\n",
    "\n",
    "                for col in pat_features.columns:\n",
    "                    pat_features[col] = pd.to_numeric(pat_features[col],errors='coerce',)\n",
    "\n",
    "                # clean aggregated patient feature data\n",
    "                pat_features.fillna(np.nan, inplace=True)\n",
    "                pat_features = pat_features.round(4)\n",
    "\n",
    "                # append data to patient list\n",
    "                patient_features.append(pat_features)\n",
    "\n",
    "                # increment patient index counter\n",
    "                n+=1\n",
    "\n",
    "                if debug:\n",
    "                    stop = 5\n",
    "                    if n >= stop:\n",
    "                        break\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    \n",
    "    # save patient features\n",
    "    TYPE = 'static'\n",
    "    static_dir = config['DIR']['data'].format(RUN=RUN,TYPE=TYPE)\n",
    "    filename = \"processed_data_patient_features.csv\"\n",
    "    pat_feat_outpath = os.path.join(static_dir,filename)\n",
    "\n",
    "    # combine patient feature data into dataframe\n",
    "    final = pd.concat(patient_features,axis=0)\n",
    "    if not debug:\n",
    "        # save\n",
    "        final.to_csv(pat_feat_outpath)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
